"""
ìë™í™”ëœ ì •í™•ë„ ìµœì í™” ì‹œìŠ¤í…œ

Gemini 2.5 Flashë¡œ í…ŒìŠ¤íŠ¸ â†’ Gemini 2.5 Proë¡œ ë¶„ì„ ë° ê°œì„  â†’ ë°˜ë³µ
"""

import os
import json
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import logging

from .gemini_flash_classifier import GeminiFlashClassifier
from .gemini_pro_analyzer import GeminiProAnalyzer
from .kt_score_calculator import KTScoreCalculator
from config import OptimizationConfig

logger = logging.getLogger(__name__)

@dataclass
class ErrorAnalysis:
    """ì˜¤ë‹µ ë¶„ì„ ê²°ê³¼"""
    wrong_questions: List[str]
    wrong_predictions: List[str]
    correct_answers: List[str]
    error_patterns: List[str]
    improvement_suggestions: List[str]

@dataclass
class OptimizationIteration:
    """ìµœì í™” ë°˜ë³µ ê¸°ë¡"""
    iteration: int
    timestamp: str
    prompt_path: str
    accuracy: float
    kt_score: float
    error_count: int
    improvements: List[str]

class AutoAccuracyOptimizer:
    """ìë™í™”ëœ ì •í™•ë„ ìµœì í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, samples_csv_path: str = "data/samples.csv", output_dir: str = "prompt/auto_optimized"):
        self.samples_csv_path = samples_csv_path
        self.output_dir = output_dir
        self.config = OptimizationConfig.from_env()
        self.kt_calculator = KTScoreCalculator()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(output_dir, exist_ok=True)
        
        # ìµœì í™” íˆìŠ¤í† ë¦¬
        self.optimization_history: List[OptimizationIteration] = []
        
    async def optimize_accuracy_automatically(
        self, 
        initial_prompt_path: str, 
        target_accuracy: float = 0.8,
        max_iterations: int = 10
    ) -> str:
        """ìë™í™”ëœ ì •í™•ë„ ìµœì í™” ì‹¤í–‰"""
        
        logger.info(f"ìë™ ì •í™•ë„ ìµœì í™” ì‹œì‘ - ëª©í‘œ: {target_accuracy}, ìµœëŒ€ ë°˜ë³µ: {max_iterations}")
        
        current_prompt_path = initial_prompt_path
        
        for iteration in range(1, max_iterations + 1):
            logger.info(f"\n=== ë°˜ë³µ {iteration}/{max_iterations} ì‹œì‘ ===")
            
            # 1ë‹¨ê³„: Gemini 2.5 Flashë¡œ í…ŒìŠ¤íŠ¸
            accuracy, errors = await self._test_with_flash(current_prompt_path)
            
            logger.info(f"í˜„ì¬ ì •í™•ë„: {accuracy:.4f} (ëª©í‘œ: {target_accuracy})")
            
            # ëª©í‘œ ë‹¬ì„± ì‹œ ì¢…ë£Œ
            if accuracy >= target_accuracy:
                logger.info(f"ğŸ‰ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±! ìµœì¢… í”„ë¡¬í”„íŠ¸: {current_prompt_path}")
                return current_prompt_path
            
            # 2ë‹¨ê³„: Gemini 2.5 Proë¡œ ì˜¤ë‹µ ë¶„ì„
            error_analysis = await self._analyze_errors_with_pro(current_prompt_path, errors)
            
            # 3ë‹¨ê³„: Gemini 2.5 Proë¡œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
            improved_prompt_path = await self._generate_improved_prompt_with_pro(
                current_prompt_path, error_analysis, iteration
            )
            
            # íˆìŠ¤í† ë¦¬ ê¸°ë¡
            self._record_iteration(iteration, current_prompt_path, accuracy, len(errors), error_analysis.improvement_suggestions)
            
            current_prompt_path = improved_prompt_path
            
            logger.info(f"ë°˜ë³µ {iteration} ì™„ë£Œ - ë‹¤ìŒ í”„ë¡¬í”„íŠ¸: {current_prompt_path}")
        
        logger.warning(f"ìµœëŒ€ ë°˜ë³µ ìˆ˜ ë„ë‹¬. ìµœì¢… í”„ë¡¬í”„íŠ¸: {current_prompt_path}")
        return current_prompt_path
    
    async def _test_with_flash(self, prompt_path: str) -> Tuple[float, List[Dict]]:
        """Gemini 2.5 Flashë¡œ ì •í™•ë„ í…ŒìŠ¤íŠ¸ ë° ì˜¤ë‹µ ìˆ˜ì§‘"""
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            prompt_text = f.read().strip()
        
        # Flash ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        classifier = GeminiFlashClassifier(self.config, prompt_text)
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë” ë§ì€ ìƒ˜í”Œë¡œ)
        results = await classifier.test_prompt_performance(prompt_text, self.samples_csv_path)
        
        accuracy = results.get('accuracy', 0.0)
        
        # ì˜¤ë‹µ ìˆ˜ì§‘
        errors = []
        if 'detailed_results' in results:
            for result in results['detailed_results']:
                if not result.get('correct', False):
                    errors.append({
                        'question': result.get('question', ''),
                        'predicted': result.get('predicted', ''),
                        'actual': result.get('actual', ''),
                        'explanation': result.get('explanation', '')
                    })
        
        logger.info(f"í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ì •í™•ë„: {accuracy:.4f}, ì˜¤ë‹µ: {len(errors)}ê°œ")
        return accuracy, errors
    
    async def _analyze_errors_with_pro(self, prompt_path: str, errors: List[Dict]) -> ErrorAnalysis:
        """Gemini 2.5 Proë¡œ ì˜¤ë‹µ ë¶„ì„"""
        
        with open(prompt_path, 'r', encoding='utf-8') as f:
            current_prompt = f.read().strip()
        
        # ì˜¤ë‹µ ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸ ìƒì„±
        analysis_prompt = self._create_error_analysis_prompt(current_prompt, errors)
        
        # Gemini 2.5 Proë¡œ ë¶„ì„
        analyzer = GeminiProAnalyzer(self.config)
        analysis_result = await analyzer.analyze_prompt_errors(analysis_prompt)
        
        # ê²°ê³¼ íŒŒì‹±
        error_analysis = self._parse_error_analysis(analysis_result, errors)
        
        logger.info(f"ì˜¤ë‹µ ë¶„ì„ ì™„ë£Œ - íŒ¨í„´: {len(error_analysis.error_patterns)}ê°œ, ì œì•ˆ: {len(error_analysis.improvement_suggestions)}ê°œ")
        return error_analysis
    
    def _create_error_analysis_prompt(self, current_prompt: str, errors: List[Dict]) -> str:
        """ì˜¤ë‹µ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        error_examples = ""
        for i, error in enumerate(errors[:10], 1):  # ìµœëŒ€ 10ê°œ ì˜¤ë‹µë§Œ
            error_examples += f"""
ì˜¤ë‹µ {i}:
- ë¬¸ì¥: "{error['question']}"
- ì˜ˆì¸¡: {error['predicted']}
- ì •ë‹µ: {error['actual']}
"""
        
        analysis_prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ í”„ë¡¬í”„íŠ¸:
```
{current_prompt}
```

ì´ í”„ë¡¬í”„íŠ¸ë¡œ ë¶„ë¥˜í•œ ê²°ê³¼ ë‹¤ìŒê³¼ ê°™ì€ ì˜¤ë‹µë“¤ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤:
{error_examples}

ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **ì˜¤ë‹µ íŒ¨í„´ ë¶„ì„**: ì–´ë–¤ ìœ í˜•ì˜ ë¬¸ì¥ì—ì„œ ì£¼ë¡œ í‹€ë¦¬ëŠ”ê°€?
2. **í”„ë¡¬í”„íŠ¸ ë¬¸ì œì **: í˜„ì¬ í”„ë¡¬í”„íŠ¸ì˜ ì–´ë–¤ ë¶€ë¶„ì´ ì´ëŸ° ì˜¤ë‹µì„ ìœ ë°œí•˜ëŠ”ê°€?
3. **ê°œì„  ë°©í–¥**: ì´ëŸ° ì˜¤ë‹µì„ ì¤„ì´ê¸° ìœ„í•´ í”„ë¡¬í”„íŠ¸ë¥¼ ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ê°€?

ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

## ì˜¤ë‹µ íŒ¨í„´
- íŒ¨í„´ 1: ...
- íŒ¨í„´ 2: ...

## í”„ë¡¬í”„íŠ¸ ë¬¸ì œì 
- ë¬¸ì œì  1: ...
- ë¬¸ì œì  2: ...

## ê°œì„  ì œì•ˆ
- ì œì•ˆ 1: ...
- ì œì•ˆ 2: ...
"""
        
        return analysis_prompt
    
    def _parse_error_analysis(self, analysis_result: str, errors: List[Dict]) -> ErrorAnalysis:
        """ë¶„ì„ ê²°ê³¼ íŒŒì‹±"""
        
        # ê°„ë‹¨í•œ íŒŒì‹± (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ íŒŒì‹± í•„ìš”)
        error_patterns = []
        improvement_suggestions = []
        
        lines = analysis_result.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            if '## ì˜¤ë‹µ íŒ¨í„´' in line:
                current_section = 'patterns'
            elif '## ê°œì„  ì œì•ˆ' in line:
                current_section = 'suggestions'
            elif line.startswith('- ') and current_section == 'patterns':
                error_patterns.append(line[2:])
            elif line.startswith('- ') and current_section == 'suggestions':
                improvement_suggestions.append(line[2:])
        
        return ErrorAnalysis(
            wrong_questions=[e['question'] for e in errors],
            wrong_predictions=[e['predicted'] for e in errors],
            correct_answers=[e['actual'] for e in errors],
            error_patterns=error_patterns,
            improvement_suggestions=improvement_suggestions
        )
    
    async def _generate_improved_prompt_with_pro(
        self, 
        current_prompt_path: str, 
        error_analysis: ErrorAnalysis, 
        iteration: int
    ) -> str:
        """Gemini 2.5 Proë¡œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        with open(current_prompt_path, 'r', encoding='utf-8') as f:
            current_prompt = f.read().strip()
        
        # í”„ë¡¬í”„íŠ¸ ê°œì„  ìš”ì²­ ìƒì„±
        improvement_prompt = self._create_improvement_prompt(current_prompt, error_analysis)
        
        # Gemini 2.5 Proë¡œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        analyzer = GeminiProAnalyzer(self.config)
        improved_prompt = await analyzer.generate_improved_prompt(improvement_prompt)
        
        # ìƒˆ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥
        new_prompt_path = os.path.join(self.output_dir, f"auto_optimized_v{iteration}.txt")
        with open(new_prompt_path, 'w', encoding='utf-8') as f:
            f.write(improved_prompt)
        
        logger.info(f"ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±: {new_prompt_path}")
        return new_prompt_path
    
    def _create_improvement_prompt(self, current_prompt: str, error_analysis: ErrorAnalysis) -> str:
        """í”„ë¡¬í”„íŠ¸ ê°œì„  ìš”ì²­ ìƒì„±"""
        
        patterns_text = '\n'.join([f"- {p}" for p in error_analysis.error_patterns])
        suggestions_text = '\n'.join([f"- {s}" for s in error_analysis.improvement_suggestions])
        
        improvement_prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ê°œì„  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ í”„ë¡¬í”„íŠ¸:
```
{current_prompt}
```

ë¶„ì„ëœ ì˜¤ë‹µ íŒ¨í„´:
{patterns_text}

ê°œì„  ì œì•ˆì‚¬í•­:
{suggestions_text}

ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë” ì •í™•í•œ ë¶„ë¥˜ë¥¼ ìœ„í•œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ê°œì„  ì‹œ ê³ ë ¤ì‚¬í•­:
1. ì˜¤ë‹µ íŒ¨í„´ì„ í•´ê²°í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ê·œì¹™ ì¶”ê°€
2. ì• ë§¤í•œ í‘œí˜„ ì œê±° ë° êµ¬ì²´ì ì¸ ê¸°ì¤€ ì œì‹œ
3. ì‹¤ì œ ë°ì´í„° ë¶„í¬ ë°˜ì˜ (ì‚¬ì‹¤í˜• 82%, ê¸ì • 95%, ê³¼ê±° 48%, í™•ì‹¤ 92%)
4. í•œê¸€ ë¹„ìœ¨ ìœ ì§€ (í˜„ì¬ ìˆ˜ì¤€ ì´ìƒ)
5. ê¸¸ì´ëŠ” 3000ì ì´ë‚´ ìœ ì§€

ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš” (ì„¤ëª… ì—†ì´):
"""
        
        return improvement_prompt
    
    def _record_iteration(
        self, 
        iteration: int, 
        prompt_path: str, 
        accuracy: float, 
        error_count: int, 
        improvements: List[str]
    ):
        """ë°˜ë³µ ê¸°ë¡"""
        
        # KT ì ìˆ˜ ê³„ì‚°
        with open(prompt_path, 'r', encoding='utf-8') as f:
            prompt_text = f.read().strip()
        
        kt_score_breakdown = self.kt_calculator.calculate_full_score(accuracy, prompt_text)
        
        record = OptimizationIteration(
            iteration=iteration,
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            prompt_path=prompt_path,
            accuracy=accuracy,
            kt_score=kt_score_breakdown.total_score,
            error_count=error_count,
            improvements=improvements
        )
        
        self.optimization_history.append(record)
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        history_file = os.path.join(self.output_dir, "optimization_history.json")
        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump([record.__dict__ for record in self.optimization_history], f, 
                     ensure_ascii=False, indent=2)
    
    def get_optimization_report(self) -> str:
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.optimization_history:
            return "ìµœì í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        report = "# ìë™ ì •í™•ë„ ìµœì í™” ë¦¬í¬íŠ¸\n\n"
        
        # ì „ì²´ ì§„í–‰ ìƒí™©
        first_record = self.optimization_history[0]
        last_record = self.optimization_history[-1]
        
        accuracy_improvement = last_record.accuracy - first_record.accuracy
        kt_improvement = last_record.kt_score - first_record.kt_score
        
        report += f"## ì „ì²´ ì§„í–‰ ìƒí™©\n"
        report += f"- ì´ ë°˜ë³µ ìˆ˜: {len(self.optimization_history)}íšŒ\n"
        report += f"- ì‹œì‘ ì •í™•ë„: {first_record.accuracy:.4f}\n"
        report += f"- ìµœì¢… ì •í™•ë„: {last_record.accuracy:.4f}\n"
        report += f"- ì •í™•ë„ ê°œì„ : {accuracy_improvement:+.4f}\n"
        report += f"- KT ì ìˆ˜ ê°œì„ : {kt_improvement:+.4f}\n\n"
        
        # ë°˜ë³µë³„ ìƒì„¸ ê¸°ë¡
        report += "## ë°˜ë³µë³„ ìƒì„¸ ê¸°ë¡\n\n"
        for record in self.optimization_history:
            report += f"### ë°˜ë³µ {record.iteration} ({record.timestamp})\n"
            report += f"- í”„ë¡¬í”„íŠ¸: {record.prompt_path}\n"
            report += f"- ì •í™•ë„: {record.accuracy:.4f}\n"
            report += f"- KT ì ìˆ˜: {record.kt_score:.4f}\n"
            report += f"- ì˜¤ë‹µ ìˆ˜: {record.error_count}ê°œ\n"
            
            if record.improvements:
                report += "- ê°œì„ ì‚¬í•­:\n"
                for improvement in record.improvements:
                    report += f"  - {improvement}\n"
            report += "\n"
        
        return report