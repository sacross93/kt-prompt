"""
ë°˜ë³µì  ì •í™•ë„ ìµœì í™”ê¸°

Gemini 2.5 Flashë¡œ í…ŒìŠ¤íŠ¸ â†’ Gemini 2.5 Proë¡œ ë¶„ì„ â†’ í”„ë¡¬í”„íŠ¸ ê°œì„  â†’ ë°˜ë³µ
"""

import asyncio
import os
from typing import Dict, List, Tuple, Optional
import logging
from dataclasses import dataclass

from .gemini_flash_classifier import GeminiFlashClassifier
from .gemini_client import GeminiClient
from config import OptimizationConfig

logger = logging.getLogger(__name__)

@dataclass
class ErrorCase:
    """ì˜¤ë¥˜ ì‚¬ë¡€"""
    sentence: str
    predicted: str
    expected: str
    error_type: str

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    root_causes: List[str]
    improvement_suggestions: List[str]
    revised_prompt: str

class IterativeAccuracyOptimizer:
    """ë°˜ë³µì  ì •í™•ë„ ìµœì í™”ê¸°"""
    
    def __init__(self, samples_csv_path: str = "data/samples.csv"):
        self.samples_csv_path = samples_csv_path
        self.config = OptimizationConfig.from_env()
        self.gemini_client = GeminiClient(self.config)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.flash_model = self.gemini_client.get_flash_model()
        self.pro_model = self.gemini_client.get_pro_model()
        
        self.iteration_count = 0
        self.max_iterations = 10
        self.target_accuracy = 0.8
        
    async def optimize_accuracy_iteratively(self, initial_prompt: str, target_accuracy: float = 0.8) -> Tuple[str, float]:
        """ë°˜ë³µì  ì •í™•ë„ ìµœì í™”"""
        self.target_accuracy = target_accuracy
        current_prompt = initial_prompt
        best_prompt = initial_prompt
        best_accuracy = 0.0
        
        logger.info(f"ğŸ¯ ëª©í‘œ ì •í™•ë„: {target_accuracy:.2%}")
        logger.info(f"ğŸ”„ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜: {self.max_iterations}")
        
        for iteration in range(self.max_iterations):
            self.iteration_count = iteration + 1
            logger.info(f"\n=== ë°˜ë³µ {self.iteration_count}/{self.max_iterations} ===")
            
            # 1ë‹¨ê³„: Gemini 2.5 Flashë¡œ í…ŒìŠ¤íŠ¸
            logger.info("1ï¸âƒ£ Gemini 2.5 Flash í…ŒìŠ¤íŠ¸ ì¤‘...")
            accuracy, error_cases = await self._test_with_flash(current_prompt)
            
            logger.info(f"ğŸ“Š í˜„ì¬ ì •í™•ë„: {accuracy:.4f} ({accuracy:.1%})")
            
            # ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_prompt = current_prompt
                logger.info(f"ğŸ† ìµœê³  ì„±ëŠ¥ ê°±ì‹ : {best_accuracy:.4f}")
            
            # ëª©í‘œ ë‹¬ì„± í™•ì¸
            if accuracy >= target_accuracy:
                logger.info(f"ğŸ‰ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±! {accuracy:.4f} >= {target_accuracy:.4f}")
                return current_prompt, accuracy
            
            # ê°œì„  ì—¬ì§€ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            if len(error_cases) == 0:
                logger.info("âŒ ë” ì´ìƒ ê°œì„ í•  ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            # 2ë‹¨ê³„: Gemini 2.5 Proë¡œ ì˜¤ë¥˜ ë¶„ì„
            logger.info("2ï¸âƒ£ Gemini 2.5 Pro ì˜¤ë¥˜ ë¶„ì„ ì¤‘...")
            analysis = await self._analyze_errors_with_pro(current_prompt, error_cases)
            
            # 3ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ê°œì„ 
            logger.info("3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ê°œì„  ì¤‘...")
            current_prompt = analysis.revised_prompt
            
            # ê°œì„  ë‚´ìš© ë¡œê·¸
            logger.info("ğŸ“ ê°œì„  ì‚¬í•­:")
            for suggestion in analysis.improvement_suggestions[:3]:  # ìƒìœ„ 3ê°œë§Œ
                logger.info(f"   - {suggestion}")
            
            # í”„ë¡¬í”„íŠ¸ ì €ì¥
            await self._save_iteration_prompt(current_prompt, iteration + 1, accuracy)
        
        logger.info(f"\nğŸ ìµœì í™” ì™„ë£Œ - ìµœê³  ì„±ëŠ¥: {best_accuracy:.4f}")
        return best_prompt, best_accuracy
    
    async def _test_with_flash(self, prompt: str) -> Tuple[float, List[ErrorCase]]:
        """Gemini 2.5 Flashë¡œ í…ŒìŠ¤íŠ¸ ë° ì˜¤ë¥˜ ìˆ˜ì§‘"""
        try:
            # GeminiFlashClassifier ì´ˆê¸°í™”
            classifier = GeminiFlashClassifier(self.config, prompt)
            
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (100ê°œ ìƒ˜í”Œ)
            results = await classifier.test_prompt_performance(prompt, self.samples_csv_path)
            
            accuracy = results.get('accuracy', 0.0)
            errors = results.get('errors', [])
            
            # ì˜¤ë¥˜ ì‚¬ë¡€ ë³€í™˜
            error_cases = []
            for error in errors[:20]:  # ìµœëŒ€ 20ê°œ ì˜¤ë¥˜ë§Œ ë¶„ì„
                error_case = ErrorCase(
                    sentence=f"ë¬¸ì¥ {error['index']}",  # ì‹¤ì œ ë¬¸ì¥ì€ ë‚˜ì¤‘ì— ì¶”ê°€
                    predicted=error['predicted'],
                    expected=error['expected'],
                    error_type=self._classify_error_type(error['predicted'], error['expected'])
                )
                error_cases.append(error_case)
            
            return accuracy, error_cases
            
        except Exception as e:
            logger.error(f"Flash í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return 0.0, []
    
    def _classify_error_type(self, predicted: str, expected: str) -> str:
        """ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜"""
        pred_parts = predicted.split(',')
        exp_parts = expected.split(',')
        
        if len(pred_parts) != 4 or len(exp_parts) != 4:
            return "í˜•ì‹ì˜¤ë¥˜"
        
        error_attrs = []
        attrs = ['ìœ í˜•', 'ê·¹ì„±', 'ì‹œì œ', 'í™•ì‹¤ì„±']
        
        for i, attr in enumerate(attrs):
            if pred_parts[i].strip() != exp_parts[i].strip():
                error_attrs.append(attr)
        
        return '+'.join(error_attrs) if error_attrs else "ê¸°íƒ€"
    
    async def _analyze_errors_with_pro(self, current_prompt: str, error_cases: List[ErrorCase]) -> AnalysisResult:
        """Gemini 2.5 Proë¡œ ì˜¤ë¥˜ ë¶„ì„ ë° í”„ë¡¬í”„íŠ¸ ê°œì„ """
        
        # ì˜¤ë¥˜ íŒ¨í„´ ë¶„ì„
        error_summary = self._summarize_errors(error_cases)
        
        # Gemini 2.5 Pro ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        analysis_prompt = f"""
ë‹¹ì‹ ì€ í•œêµ­ì–´ ë¬¸ì¥ ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

í˜„ì¬ í”„ë¡¬í”„íŠ¸:
```
{current_prompt}
```

ë°œìƒí•œ ì˜¤ë¥˜ë“¤:
{error_summary}

ìœ„ ì˜¤ë¥˜ë“¤ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. ê·¼ë³¸ ì›ì¸ ë¶„ì„ (3-5ê°œ):
   - ì™œ ì´ëŸ° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆëŠ”ì§€ êµ¬ì²´ì  ì›ì¸

2. ê°œì„  ì œì•ˆì‚¬í•­ (3-5ê°œ):
   - ì–´ë–»ê²Œ í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ êµ¬ì²´ì  ë°©ë²•

3. ê°œì„ ëœ í”„ë¡¬í”„íŠ¸:
   - ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì™„ì „íˆ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì‘ì„±
   - ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ì˜ ì¢‹ì€ ë¶€ë¶„ì€ ìœ ì§€í•˜ë˜ ë¬¸ì œì ì€ í•´ê²°
   - í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³  ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ

ì‘ë‹µ í˜•ì‹:
## ê·¼ë³¸ ì›ì¸ ë¶„ì„
1. [ì›ì¸1]
2. [ì›ì¸2]
...

## ê°œì„  ì œì•ˆì‚¬í•­  
1. [ì œì•ˆ1]
2. [ì œì•ˆ2]
...

## ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
```
[ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸ ì „ì²´ ë‚´ìš©]
```
"""
        
        try:
            # Gemini 2.5 Proë¡œ ë¶„ì„ ìš”ì²­
            response = self.gemini_client.generate_content_with_retry(
                self.pro_model, analysis_prompt
            )
            
            # ì‘ë‹µ íŒŒì‹±
            root_causes, suggestions, revised_prompt = self._parse_pro_response(response)
            
            return AnalysisResult(
                root_causes=root_causes,
                improvement_suggestions=suggestions,
                revised_prompt=revised_prompt
            )
            
        except Exception as e:
            logger.error(f"Pro ë¶„ì„ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê°œì„ ì•ˆ ë°˜í™˜
            return AnalysisResult(
                root_causes=["ë¶„ì„ ì‹¤íŒ¨"],
                improvement_suggestions=["ê¸°ë³¸ ê°œì„  ì ìš©"],
                revised_prompt=current_prompt  # ì›ë³¸ ìœ ì§€
            )
    
    def _summarize_errors(self, error_cases: List[ErrorCase]) -> str:
        """ì˜¤ë¥˜ ìš”ì•½"""
        if not error_cases:
            return "ì˜¤ë¥˜ ì—†ìŒ"
        
        # ì˜¤ë¥˜ ìœ í˜•ë³„ ì§‘ê³„
        error_types = {}
        for case in error_cases:
            error_types[case.error_type] = error_types.get(case.error_type, 0) + 1
        
        summary = f"ì´ {len(error_cases)}ê°œ ì˜¤ë¥˜:\n"
        
        # ìƒìœ„ ì˜¤ë¥˜ ìœ í˜•ë“¤
        for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True)[:5]:
            summary += f"- {error_type}: {count}ê°œ\n"
        
        # êµ¬ì²´ì  ì˜¤ë¥˜ ì˜ˆì‹œ (ìƒìœ„ 5ê°œ)
        summary += "\nêµ¬ì²´ì  ì˜¤ë¥˜ ì˜ˆì‹œ:\n"
        for i, case in enumerate(error_cases[:5]):
            summary += f"{i+1}. ì˜ˆì¸¡: {case.predicted} â†’ ì •ë‹µ: {case.expected} (ìœ í˜•: {case.error_type})\n"
        
        return summary
    
    def _parse_pro_response(self, response: str) -> Tuple[List[str], List[str], str]:
        """Gemini Pro ì‘ë‹µ íŒŒì‹±"""
        try:
            lines = response.split('\n')
            
            root_causes = []
            suggestions = []
            revised_prompt = ""
            
            current_section = None
            in_prompt = False
            
            for line in lines:
                line = line.strip()
                
                if "ê·¼ë³¸ ì›ì¸" in line or "ì›ì¸ ë¶„ì„" in line:
                    current_section = "causes"
                elif "ê°œì„  ì œì•ˆ" in line or "ì œì•ˆì‚¬í•­" in line:
                    current_section = "suggestions"
                elif "ê°œì„ ëœ í”„ë¡¬í”„íŠ¸" in line or "ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸" in line:
                    current_section = "prompt"
                elif line.startswith("```"):
                    in_prompt = not in_prompt
                    continue
                
                if current_section == "causes" and line.startswith(("1.", "2.", "3.", "4.", "5.", "-")):
                    root_causes.append(line[2:].strip())
                elif current_section == "suggestions" and line.startswith(("1.", "2.", "3.", "4.", "5.", "-")):
                    suggestions.append(line[2:].strip())
                elif current_section == "prompt" and in_prompt:
                    revised_prompt += line + "\n"
            
            # í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì‘ë‹µ ì „ì²´ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
            if not revised_prompt.strip():
                # ë§ˆì§€ë§‰ ``` ì´í›„ ë‚´ìš©ì„ í”„ë¡¬í”„íŠ¸ë¡œ ì¶”ì¶œ
                prompt_start = response.rfind("```")
                if prompt_start != -1:
                    revised_prompt = response[prompt_start+3:].strip()
                else:
                    revised_prompt = response  # ì „ì²´ ì‘ë‹µ ì‚¬ìš©
            
            return root_causes, suggestions, revised_prompt.strip()
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return [], [], response  # ì‹¤íŒ¨ ì‹œ ì „ì²´ ì‘ë‹µì„ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
    
    async def _save_iteration_prompt(self, prompt: str, iteration: int, accuracy: float):
        """ë°˜ë³µë³„ í”„ë¡¬í”„íŠ¸ ì €ì¥"""
        try:
            os.makedirs("prompt/gemini/iterations", exist_ok=True)
            filename = f"prompt/gemini/iterations/iteration_{iteration:02d}_acc_{accuracy:.4f}.txt"
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(prompt)
            
            logger.info(f"ğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥: {filename}")
            
        except Exception as e:
            logger.error(f"í”„ë¡¬í”„íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")