import pandas as pd
import openai
import os
from dotenv import load_dotenv
import time
import random
import re

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
api_key = os.getenv('OPENAI_API_KEY')

def load_system_prompt(file_path):
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()

def test_classification_gpt4o(system_prompt, test_sentences, model="gpt-4o", temperature=0.4):
    """GPT-4oë¥¼ ì‚¬ìš©í•œ ë¬¸ì¥ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸"""
    # ì…ë ¥ í˜•ì‹ ìƒì„±
    user_input = ""
    for i, sentence in enumerate(test_sentences, 1):
        user_input += f"{i}. {sentence}\n"
    
    try:
        client = openai.OpenAI(api_key=api_key)
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input.strip()}
            ],
            temperature=temperature,
            max_tokens=1000
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        return f"Error: {str(e)}"

def calculate_accuracy(predictions, ground_truth):
    """ë¶„ë¥˜ ì •í™•ë„ ê³„ì‚°"""
    if len(predictions) != len(ground_truth):
        print(f"ê¸¸ì´ ë¶ˆì¼ì¹˜: ì˜ˆì¸¡ {len(predictions)}, ì •ë‹µ {len(ground_truth)}")
        return 0.0
    
    total_correct = 0
    total_attributes = 0
    attribute_correct = [0, 0, 0, 0]  # ìœ í˜•, ê·¹ì„±, ì‹œì œ, í™•ì‹¤ì„±
    
    for pred, truth in zip(predictions, ground_truth):
        pred_parts = pred.split(',')
        truth_parts = truth.split(',')
        
        if len(pred_parts) == 4 and len(truth_parts) == 4:
            for i, (p, t) in enumerate(zip(pred_parts, truth_parts)):
                if p.strip() == t.strip():
                    total_correct += 1
                    attribute_correct[i] += 1
                total_attributes += 1
    
    overall_accuracy = total_correct / total_attributes if total_attributes > 0 else 0.0
    
    # ì†ì„±ë³„ ì •í™•ë„
    attr_names = ['ìœ í˜•', 'ê·¹ì„±', 'ì‹œì œ', 'í™•ì‹¤ì„±']
    attr_accuracies = []
    for i, correct in enumerate(attribute_correct):
        acc = correct / len(predictions) if len(predictions) > 0 else 0.0
        attr_accuracies.append(acc)
        print(f"{attr_names[i]} ì •í™•ë„: {acc:.1%}")
    
    return overall_accuracy

def calculate_korean_ratio(text):
    """í•œê¸€ ë¬¸ì ë¹„ìœ¨ ê³„ì‚°"""
    korean_chars = 0
    total_chars = 0
    
    for char in text:
        if char not in [' ', '\n', '\t']:
            total_chars += 1
            if 'ê°€' <= char <= 'í£':
                korean_chars += 1
    
    return korean_chars / total_chars if total_chars > 0 else 0.0

def run_gpt4o_test(system_prompt_path, sample_size=20, temperature=0.4):
    """GPT-4o í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('data/samples.csv')
    
    # ëœë¤ ìƒ˜í”Œ ì„ íƒ
    sample_df = df.sample(n=sample_size)
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    system_prompt = load_system_prompt(system_prompt_path)
    
    print(f"=== GPT-4o ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ({sample_size}ê°œ ìƒ˜í”Œ) ===")
    print(f"ëª¨ë¸: gpt-4o")
    print(f"Temperature: {temperature}")
    print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(system_prompt)}ì")
    print(f"í•œê¸€ ë¹„ìœ¨: {calculate_korean_ratio(system_prompt):.1%}")
    print()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_sentences = sample_df['user_prompt'].tolist()
    ground_truth = sample_df['output'].tolist()
    
    print("í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    start_time = time.time()
    result = test_classification_gpt4o(system_prompt, test_sentences, temperature=temperature)
    end_time = time.time()
    
    print(f"ì‘ë‹µ ì‹œê°„: {end_time - start_time:.1f}ì´ˆ")
    print()
    
    print("=== ëª¨ë¸ ì¶œë ¥ ===")
    print(result)
    print()
    
    # ê²°ê³¼ íŒŒì‹± ë° ì •í™•ë„ ê³„ì‚°
    try:
        predictions = []
        for line in result.split('\n'):
            line = line.strip()
            # "1. ì‚¬ì‹¤í˜•,ê¸ì •,í˜„ì¬,í™•ì‹¤" í˜•ì‹ ì²˜ë¦¬
            if line and re.match(r'^\d+\.', line):
                # ë²ˆí˜¸ì™€ ì  ë‹¤ìŒì˜ ë‚´ìš© ì¶”ì¶œ
                parts = re.split(r'^\d+\.?\s*', line, 1)
                if len(parts) == 2:
                    pred = parts[1].strip()
                    predictions.append(pred)
        
        print(f"=== ì„±ëŠ¥ í‰ê°€ ===")
        print(f"ì˜ˆì¸¡ ê°œìˆ˜: {len(predictions)}")
        print(f"ì‹¤ì œ ê°œìˆ˜: {len(ground_truth)}")
        
        if len(predictions) > 0:
            accuracy = calculate_accuracy(predictions, ground_truth)
            print(f"ì „ì²´ ë¶„ë¥˜ ì •í™•ë„: {accuracy:.1%}")
            
            # ëŒ€íšŒ ì ìˆ˜ ê³„ì‚°
            korean_ratio = calculate_korean_ratio(system_prompt)
            length_score = min(1.0, (3000 - len(system_prompt)) / 3000 + 0.5)  # ê¸¸ì´ ì ìˆ˜ ì¶”ì •
            total_score = 0.8 * accuracy + 0.1 * korean_ratio + 0.1 * length_score
            print(f"ì˜ˆìƒ ëŒ€íšŒ ì ìˆ˜: {total_score:.1%}")
            
            return accuracy
        
        # ìƒì„¸ ë¹„êµ (ì²˜ìŒ 10ê°œë§Œ)
        print("\n=== ìƒì„¸ ë¹„êµ (ì²˜ìŒ 10ê°œ) ===")
        for i in range(min(10, len(predictions), len(ground_truth))):
            print(f"{i+1}. {test_sentences[i]}")
            print(f"   ì˜ˆì¸¡: {predictions[i] if i < len(predictions) else 'N/A'}")
            print(f"   ì •ë‹µ: {ground_truth[i]}")
            
            # ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
            if i < len(predictions):
                pred_parts = predictions[i].split(',')
                truth_parts = ground_truth[i].split(',')
                if len(pred_parts) == 4 and len(truth_parts) == 4:
                    matches = [p.strip() == t.strip() for p, t in zip(pred_parts, truth_parts)]
                    match_str = " ".join(["âœ“" if m else "âœ—" for m in matches])
                    print(f"   ì¼ì¹˜: {match_str} (ìœ í˜• ê·¹ì„± ì‹œì œ í™•ì‹¤ì„±)")
            print()
            
    except Exception as e:
        print(f"ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return 0.0

def iterative_improvement(target_accuracy=0.8, max_iterations=5):
    """ë°˜ë³µì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ê°œì„ í•˜ì—¬ ëª©í‘œ ì •í™•ë„ ë‹¬ì„±"""
    
    prompts_to_test = [
        'system_prompt_optimized.txt',
        'system_prompt_v1.txt', 
        'system_prompt_v2.txt',
        'system_prompt_final.txt'
    ]
    
    best_accuracy = 0.0
    best_prompt = None
    
    for i, prompt_file in enumerate(prompts_to_test):
        print(f"\n{'='*60}")
        print(f"í…ŒìŠ¤íŠ¸ {i+1}/{len(prompts_to_test)}: {prompt_file}")
        print('='*60)
        
        try:
            accuracy = run_gpt4o_test(prompt_file, sample_size=30, temperature=0.4)
            
            if accuracy > best_accuracy:
                best_accuracy = accuracy
                best_prompt = prompt_file
                
            print(f"\ní˜„ì¬ ìµœê³  ì •í™•ë„: {best_accuracy:.1%} ({best_prompt})")
            
            if accuracy >= target_accuracy:
                print(f"\nğŸ‰ ëª©í‘œ ì •í™•ë„ {target_accuracy:.1%} ë‹¬ì„±!")
                print(f"ìµœì¢… ì„ íƒ: {prompt_file} (ì •í™•ë„: {accuracy:.1%})")
                return prompt_file, accuracy
                
        except Exception as e:
            print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            continue
    
    print(f"\nìµœì¢… ê²°ê³¼: ìµœê³  ì •í™•ë„ {best_accuracy:.1%} ({best_prompt})")
    return best_prompt, best_accuracy

if __name__ == "__main__":
    # ëª©í‘œ ì •í™•ë„ 0.8 ë‹¬ì„±ê¹Œì§€ ë°˜ë³µ í…ŒìŠ¤íŠ¸
    best_prompt, final_accuracy = iterative_improvement(target_accuracy=0.8)
    
    if final_accuracy >= 0.8:
        print(f"\nâœ… ì„±ê³µ: {best_prompt}ë¡œ {final_accuracy:.1%} ì •í™•ë„ ë‹¬ì„±!")
    else:
        print(f"\nâš ï¸  ëª©í‘œ ë¯¸ë‹¬ì„±: ìµœê³  {final_accuracy:.1%} ì •í™•ë„")
        print("ì¶”ê°€ í”„ë¡¬í”„íŠ¸ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")